Архитектура Потоков Данных и Взаимодействия Проекта "Голографические Медиа"

1. Сценарий: Взаимодействие Пользователя с Голограммой (Жест -> Звук/Визуализация)
Ввод Пользователя (Frontend):
Жест: Пользователь совершает жест рукой перед камерой.
Захват: frontend/js/multimodal/handsTracking.js (используя MediaPipe) захватывает координаты ключевых точек руки (landmark_data).
Видео/Аудио Контекст: Одновременно frontend/js/core/dataCapture.js (или аналогичный модуль) может захватывать короткий видеофрагмент (video_chunk) и аудиофон (audio_chunk).
Формирование "Чанка": Эти данные (landmark_data, video_chunk, audio_chunk, timestamp, user_id, возможно, предварительная классификация жеста, если есть на клиенте) упаковываются в "комбинированный аудио(видео)-жестовый чанк" (interaction_chunk).
Отправка:
  - Медиа-файлы ("чанки"): Загружаются напрямую из клиента в **Firebase Storage** (например, по пути `user_uploads/<user_id>/<chunk_id>`) с использованием Firebase SDK.
  - Метаданные/команды: Отправляются через HTTPS-запросы к **Firebase Cloud Functions** (например, функция `processChunkMetadata` или `triaChatHandler`). Все запросы защищены **Firebase Authentication** (проверка JWT токена).
Обработка на Бэкенде (Firebase Cloud Functions, основная логика в `backend/core/`):
Прием и Валидация:
  - Для файловых "чанков": **Firebase Cloud Function**, триггерящаяся событием Firebase Storage (например, `finalize` при создании объекта). Функция получает метаданные файла и `user_id` из пути или метаданных объекта Storage.
  - Для прямых команд/запросов: HTTP-триггер **Firebase Cloud Function** (например, `triaChatHandler`). Функция получает данные запроса, валидирует их структуру и JWT токен пользователя.
Сохранение Сырых Данных и Метаданных: Cloud Function сохраняет метаданные "чанка" (включая ссылку на файл в Firebase Storage) в базу данных **Neon.tech PostgreSQL** (например, таблица `audiovisual_gestural_chunks` или `raw_interactions`). Данные привязываются к `user_id`.
Передача Оркестратору Триа (модуль в `backend/core/tria_logic.py` или будущий Genkit flow): Обрабатывающая Cloud Function инициирует логику Триа, передавая ей данные "чанка" и `user_id`.
Работа Ботов (модули в `backend/core/tria_bots/`, вызываемые из Cloud Functions или Genkit flows):
  - GestureBot: Анализирует `landmark_data` (извлеченные на клиенте и переданные как часть метаданных или отдельным вызовом CF) и `video_chunk` (ссылка на файл в Firebase Storage). Классифицирует жест, извлекает параметры, генерирует `gesture_embedding`.
  - AudioBot: Анализирует `audio_chunk` (ссылка на файл в Firebase Storage) для контекста или синтеза ответного звука.
  - MemoryBot (RAG): Используя эмбеддинги, осуществляет семантический поиск в базе знаний **Neon.tech PostgreSQL** (таблицы с использованием pgvector), учитывая также пользовательские данные и предпочтения из `user_gestures`, `user_holograms`.
  - LearningBot (асинхронно, например, через Cloud Function, триггерящуюся событием Pub/Sub): Получает "чанк", результат его обработки и обратную связь пользователя для обновления моделей и базы знаний. Эволюционный принцип сохраняется.
Формирование Ответа Триа: Оркестратор Триа (или основной Genkit flow) собирает информацию от ботов и формирует комплексный ответ. Это может быть:
  - Команды для изменения 3D-голограммы на клиенте.
  - Аудио для воспроизведения (например, ссылка на сгенерированный файл в Storage или параметры для синтеза на клиенте).
  - Текстовый ответ для чата.
Отправка Ответа: Ответ отправляется на фронтенд как HTTP-response от вызванной Cloud Function. Для будущих реалтайм обновлений могут рассматриваться Firestore listeners или WebSockets (R&D).
Реакция на Фронтенде:
Обновление Голограммы: `frontend/js/3d/rendering.js` (или `hologramRenderer.js`) получает команду и обновляет 3D-сцену.
Воспроизведение Аудио: `frontend/js/audio/audioFilePlayer.js` воспроизводит звук.
Отображение в Чате: `frontend/js/panels/chatMessages.js` отображает текстовый ответ.
2. Сценарий: Обучение Триа ("Триа собирает себя сама" через Эволюционный Принцип – Firebase/Genkit)
Сбор Данных: Пользовательские взаимодействия ("чанки" в Firebase Storage, метаданные в Neon.tech PostgreSQL) и обратная связь от пользователя сохраняются с привязкой к `user_id`.
Работа LearningBot (Firebase Cloud Function / Genkit Flow):
Анализ Эффективности: LearningBot (реализованный как Cloud Function, возможно, запускаемый по расписанию или Pub/Sub, или как Genkit flow) периодически анализирует накопленные данные. Оценивает, какие конфигурации/модели других ботов были наиболее успешны.
Генерация и Мутация: На основе анализа, LearningBot может:
Мутировать параметры существующих моделей ботов (например, немного изменить пороги в GestureBot).
Генерировать новые варианты конфигураций ботов или даже предлагать новые эвристики/правила.
Использовать генетические алгоритмы для "скрещивания" успешных конфигураций и получения новых, потенциально лучших.
Отбор: Новые/мутировавшие варианты ботов тестируются (возможно, на отложенной выборке данных или в "песочнице"). Лучшие варианты (по метрикам) становятся активными или повышают свой "вес" в ансамбле.
Обновление Базы Знаний: Успешные паттерны "жест-смысл-реакция" с их векторными представлениями сохраняются/обновляются в learned_patterns MemoryBot-ом.
Адаптация Других Ботов: Обновленные модели/параметры от LearningBot распространяются на соответствующие инстансы ботов.
3. Поток Данных для "Инфокойн" (Концептуально)
*   Каждый полезный "чанк" данных от пользователя, который способствует обучению Триа (особенно с подтвержденной обратной связью), может генерировать пользователю "Инфокойны".
*   Вычислительные ресурсы, предоставленные пользователями для локальной обработки или P2P-сети, также могут вознаграждаться.
*   Смарт-контракты на блокчейне управляют эмиссией и распределением токенов.

*Устаревшая информация в этом разделе была удалена или перенесена. Актуальное описание архитектуры см. в предыдущих разделах и в `SYSTEM_INSTRUCTION_CURRENT.md`.*

Глоссарий Ключевых Терминов, Файлов и Папок Проекта (Актуализированный)
Архитектура Проекта "Голографические Медиа" (Фокус на Firebase MVP)
Версия документа: 1.1 (Эта версия документа отражает переход на Firebase)
Дата последнего обновления: 09 Июля 2024 г.
1. Введение
Этот документ описывает высокоуровневую архитектуру, ключевые компоненты и потоки данных проекта "Голографические Медиа" (holograms.media), с акцентом на реализацию MVP в экосистеме Firebase/Google Cloud. Цель проекта – создание инновационной мультимодальной платформы для взаимодействия человека с информацией и AI через динамические 3D-аудиовизуализации ("голограммы"), а также разработка самообучающегося AI-ассистента "Триа".
2. Основные Концепции и Философия (Firebase MVP Контекст)
Голограмма (Hologram): Центральный элемент взаимодействия; динамическая, интерактивная 3D-аудиовизуализация данных. Для MVP рендерится с помощью Three.js/WebGL на Firebase Hosting, в перспективе – WebGPU.
Триа (Tria): AI-ядро проекта. На этапе MVP – набор логик, реализованных в Firebase Cloud Functions (Python), использующих прямые вызовы LLM API. В перспективе – сеть специализированных, эволюционирующих ботов, оркестрируемых с помощью Genkit и интегрированных с Firebase AI (Vertex AI).
Комбинированный Чанк Взаимодействия (Interaction Chunk): Синхронизированный набор данных (аудио, видео, жесты, метаданные), фиксирующий одно взаимодействие пользователя с системой. Является основной "пищей" для обучения Триа. Загружается в Firebase Storage, метаданные сохраняются в Neon.tech PostgreSQL.
Преодоление Симуляционно-Реального Разрыва: Обучение Триа на разнообразных реальных данных от множества пользователей для создания робастной и адаптивной AI-модели.
Новый Язык Коммуникации: Долгосрочная цель – формирование интуитивного языка, объединяющего звук, образ и жест.
HoloGraph: Децентрализованная экономическая экосистема на базе токенов (долгосрочное R&D).
3. Архитектура Потоков Данных и Взаимодействия (Firebase MVP)
3.1. Сценарий: Взаимодействие Пользователя с Голограммой (Жест -> Звук/Визуализация) – Обновлено для Firebase
Этот сценарий описывает основной цикл взаимодействия пользователя с системой в рамках MVP на Firebase.
Ввод Пользователя (Клиент / Frontend на Firebase Hosting):
Источник: Жесты рук пользователя (захват MediaPipe на клиенте), голос (Web Speech API), загрузка файлов.
Захват:
  - Жесты: Модуль `frontend/js/multimodal/handsTracking.js` захватывает `landmark_data`.
  - Аудио/Видео для "Чанка": Пользователь выбирает файл для загрузки через UI.
Формирование "Чанка" (Interaction Chunk):
  - Клиентский JavaScript (`frontend/js/services/firebaseStorageService.js`) формирует объект с метаданными (например, тип данных, `timestamp`, `user_id` от Firebase Auth). Файл медиа готовится к загрузке.
Отправка на Бэкенд:
  - Медиа-файлы: Загружаются напрямую из клиента в **Firebase Storage** (например, по пути `user_uploads/<user_id>/<chunk_id>`) с использованием Firebase SDK.
  - Метаданные/команды: Отправляются через HTTPS-запросы (используя `frontend/js/services/apiService.js`) к **Firebase Cloud Functions** (например, функция `processChunkMetadata` или `triaChatHandler`). Все запросы защищены **Firebase Authentication** (проверка JWT токена).
Обработка на Сервере (Бэкенд / Firebase Cloud Functions, логика в `backend/core/`):
Триггеры и Выполнение Функций:
  - **Firebase Storage Trigger**: Cloud Function (например, `onChunkUploaded` в `backend/main.py` или `backend/cloud_functions/process_chunk/main.py`) автоматически запускается при загрузке нового файла в Storage. Получает метаданные файла и `user_id`.
  - **HTTP Trigger**: Cloud Functions (например, `triaChatHandler` в `backend/main.py` или `backend/cloud_functions/tria_chat_handler/main.py`) вызываются фронтендом для обработки текстовых команд, сохранения пользовательских данных и т.д.
Валидация и Аутентификация: Каждая HTTP Cloud Function проверяет JWT токен пользователя через Firebase Authentication (с использованием `firebase_admin.auth` на стороне сервера).
Сохранение Данных: Cloud Functions используют `asyncpg` (через модули в `backend/core/db/`) для сохранения/извлечения данных в/из **Neon.tech PostgreSQL**. Сохраняются метаданные чанков (ссылка на файл в Storage, `user_id`, `timestamp` и др.), пользовательские жесты, состояния голограмм, история чата в соответствующие таблицы (`audiovisual_gestural_chunks`, `user_gestures`, `user_holograms`, `user_chat_sessions`, `chat_history`).
Логика Триа (внутри Cloud Functions для MVP):
  - Простая обработка: Для MVP, Триа-логика (например, в `triaChatHandler` или `onChunkUploaded`) может включать прямые вызовы LLM API (Google Gemini, Mistral) с использованием клиентов из `backend/core/services/llm_service.py`.
  - Модули Ботов (`backend/core/tria_bots/`): Концептуально, логика может быть структурирована с использованием модулей `ChatBot.py`, `ChunkProcessorBot.py`, `MemoryBot.py` (с RAG из Neon.tech), вызываемых внутри Cloud Functions.
  - LearningBot (асинхронно, Post-MVP): Может быть реализован как отдельная Cloud Function, триггерящаяся, например, по таймеру или событию Pub/Sub, для обработки накопленных данных и обратной связи.
Формирование Ответа Триа: Cloud Function формирует ответ (текст, команды для UI/голограммы).
Отправка Ответа на Фронтенд: Ответ возвращается как HTTP-response от Cloud Function.
Реакция на Клиенте (Фронтенд):
Обновление Голограммы: Модуль `frontend/js/3d/rendering.js` (или `hologramRenderer.js`) обновляет сцену.
Воспроизведение Аудио: `frontend/js/audio/audioFilePlayer.js` (если ответ содержит аудио).
Отображение в Чате: `frontend/js/panels/chatMessages.js` отображает текстовые ответы.
API для Пользовательских Данных (реализовано через HTTP Cloud Functions):
Функции для управления пользовательскими жестами, состояниями голограмм, сессиями чата и промптами доступны через защищенные HTTP-эндпоинты, реализованные как Firebase Cloud Functions. Логика этих функций находится в соответствующих Cloud Functions (например, в `backend/main.py` или `backend/cloud_functions/`), которые используют общие модули из `backend/core/` (например, `crud_operations.py`) для работы с Neon.tech PostgreSQL.

3.2. Сценарий: Обучение Триа и Эволюция ("Триа собирает себя сама" – Firebase/Genkit)
(Этот раздел остается концептуально схожим, но с уточнениями по технологиям)
Непрерывный Сбор Данных: Все Interaction Chunks (метаданные в Neon.tech, файлы в Firebase Storage) и обратная связь от пользователя сохраняются с привязкой к `user_id`.
Работа LearningBot (Firebase Cloud Function / Genkit Flow):
Анализ Эффективности: LearningBot (реализованный как Cloud Function, возможно, запускаемый по расписанию или Pub/Sub, или как Genkit flow) периодически анализирует данные.
Эволюционный Цикл (с Genkit):
  - Генерация/Мутация: LearningBot flow предлагает изменения в параметрах других ботов/flows или генерирует новые.
  - Отбор (Валидация): Тестирование вариантов на исторических данных или через A/B тесты.
  - Обновление Базы Знаний и Моделей: Обновление данных в Neon.tech PostgreSQL и, возможно, переобучение/файн-тюнинг моделей (например, через Vertex AI).
Адаптация Других Ботов/Flows: Обновленные конфигурации распространяются.
Этот сценарий описывает, как Триа обучается и самосовершенствуется.
Непрерывный Сбор Данных: Все Interaction Chunks и явная/неявная обратная связь от пользователя (лайки/дизлайки, коррекции, время взаимодействия с определенным контентом, достижение цели) постоянно собираются и сохраняются в PostgreSQL. **Данные привязываются к `user_id`.**
Работа LearningBot (Бэкенд, фоновый/периодический процесс):
Анализ Эффективности: LearningBot регулярно анализирует накопленную базу взаимодействий и обратной связи. Он оценивает, какие конфигурации моделей, параметры, эвристики и цепочки вызовов других ботов (например, GestureBot -> MemoryBot -> AudioBot) привели к наиболее успешным результатам (высокая точность, положительная обратная связь, достижение целей пользователя).
Эволюционный Цикл:
Генерация/Мутация: На основе анализа, LearningBot проактивно:
Мутирует параметры существующих моделей ботов (например, изменяет архитектуру нейронной сети в GestureBot, подбирает веса в ансамбле моделей, корректирует пороги чувствительности).
Генерирует новые варианты конфигураций ботов, может предлагать новые типы признаков для анализа или даже новые простые эвристики/правила.
Использует генетические алгоритмы или другие методы оптимизации для "скрещивания" успешных "геномов" (конфигураций) ботов и поиска новых, более эффективных комбинаций.
Отбор (Валидация): Новые или мутировавшие варианты конфигураций ботов проходят тестирование:
На отложенной выборке исторических данных.
В "песочнице" или через A/B тестирование на небольшой группе пользователей (с их согласия).
Оцениваются по predefined метрикам (точность, скорость, ресурсоемкость, удовлетворенность пользователя).
Лучшие, наиболее эффективные варианты конфигураций ботов становятся основными (активными) или повышают свой "вес" в системе принятия решений.
Обновление Глобальной Базы Знаний: LearningBot совместно с MemoryBot обновляет общую базу знаний Триа:
Успешные и подтвержденные паттерны "ввод_пользователя -> интерпретация_триа -> реакция_триа -> результат/обратная_связь" и их векторные представления сохраняются/усиливаются.
Неудачные или устаревшие паттерны ослабляются или удаляются.
Адаптация Других Ботов: Обновленные модели, параметры или знания, сгенерированные LearningBot, распространяются на соответствующие инстансы ботов, улучшая их индивидуальную и коллективную производительность.
3.3. Поток Данных и Ценности в Экосистеме "HoloGraph" (Концептуально)
Создание Ценности Пользователем:
Каждый качественный Interaction Chunk, предоставленный пользователем (особенно с явной и полезной обратной связью), который способствует обучению и улучшению Триа, регистрируется системой.
Предоставление пользователем вычислительных ресурсов (например, для локального обучения частичных моделей Триа или участия в P2P-сети для распределенных вычислений/хранения) также регистрируется.
Начисление Токенов HoloGraph:
На основе зарегистрированного вклада (данные, ресурсы, обратная связь) пользователю начисляются токены HoloGraph. Логика начисления определяется смарт-контрактами.
Использование Токенов HoloGraph:
Доступ к премиум-функциям платформы.
Участие в управлении развитием Триа и платформы (DAO – Decentralized Autonomous Organization).
Оплата вычислительных ресурсов или специализированных сервисов внутри экосистемы.
Стимулирование разработчиков за создание полезных модулей/ботов для Триа.
Самофинансирование Триа: Часть токенов может направляться на оплату облачных ресурсов для глобального обучения Триа, исследований и дальнейшего развития платформы.
4. Глоссарий Ключевых Терминов, Файлов и Папок (Актуализировано для Firebase MVP)
Этот раздел поддерживается в актуальном состоянии, чтобы отражать текущую структуру и терминологию проекта.
**Важно:** Все таблицы, связанные с пользовательскими данными (например, `user_gestures`, `user_holograms`, `user_chat_sessions`), теперь строго привязаны к `users.id` (из Firebase Authentication) через внешние ключи в Neon.tech PostgreSQL.

Основные Концепции (пересмотрены для Firebase MVP):
Голограмма (Hologram): Динамическая 3D аудиовизуализация. MVP использует Three.js/WebGL. WebGPU – R&D.
Триа (Tria): AI-ассистент. MVP – логика в Firebase Cloud Functions (Python), прямые вызовы LLM. Будущее – Genkit, Firebase AI/Vertex AI.
Комбинированный Аудио(Видео)-Жестовый Чанк (Interaction Chunk): Данные взаимодействия пользователя. Загружаются в Firebase Storage, метаданные в Neon.tech PostgreSQL.
Firebase Ecosystem: Основа инфраструктуры MVP (Hosting, Functions, Storage, Auth, Emulator Suite).
Neon.tech PostgreSQL + pgvector: Активная база данных для MVP.
Genkit: Целевой фреймворк для оркестрации AI-логики Триа (post-MVP).

Ключевые Директории и Файлы Проекта (Актуализировано для Firebase):
`backend/`: Содержит Python-код для Firebase Cloud Functions.
  `backend/main.py`: Может служить основным файлом для определения нескольких Firebase Cloud Functions или импортировать их из поддиректории `cloud_functions`.
  `backend/cloud_functions/`: (Рекомендуемая структура для MVP и далее) Директория для отдельных модулей Cloud Functions, сгруппированных по назначению (например, `auth_sync.py` для синхронизации пользователей, `process_chunk.py` для обработки загрузок, `tria_chat_handler.py` для чата Триа).
  `backend/core/`: Общая переиспользуемая логика, импортируемая Cloud Functions:
    `backend/core/db/`: Модули для работы с Neon.tech PostgreSQL (например, `pg_connector.py` для установки соединения, `crud_operations.py` для операций с данными, `schema.sql` для определения структуры БД).
    `backend/core/models/`: Pydantic модели для валидации данных API и структуры таблиц БД.
    `backend/core/services/`: Клиенты и сервисы для взаимодействия с внешними API (например, `llm_service.py` для Google Gemini, Mistral API).
    `backend/core/tria_bots/`: Логика отдельных ботов Триа (`ChatBot.py`, `MemoryBot.py`, `GestureBot.py` и т.д.).
  `backend/requirements.txt`: Список Python-зависимостей для окружения Cloud Functions.
  `backend/tests/`: Юнит-тесты (Pytest) для логики в `backend/core/` и интеграционные тесты для Cloud Functions (с использованием Firebase Local Emulator Suite).
`frontend/`: Код фронтенда, развертываемый на Firebase Hosting.
  `frontend/index.html`: Основная HTML-страница (SPA).
  `frontend/js/`: Корневая директория для JavaScript ES6 модулей.
    `frontend/js/main.js`: Главная точка входа для фронтенда, инициализирует остальные модули.
    `frontend/js/services/apiService.js`: Отправляет HTTP-запросы к Firebase Cloud Functions.
    `frontend/js/services/firebaseStorageService.js`: Управляет загрузкой файлов в Firebase Storage.
    `frontend/js/core/auth.js`: Интеграция с Firebase Authentication на клиенте.
`docs/`: Вся проектная документация.
  `docs/03_SYSTEM_INSTRUCTIONS_AI/SYSTEM_INSTRUCTION_CURRENT.md`: Основная системная инструкция (этот документ).
  `docs/01_ARCHITECTURE/SYSTEM_ARCHITECTURE.md`: Детальное описание архитектуры (этот документ).
  `docs/05_PLANNING_AND_TASKS/ULTIMATE_ROAD_TO_MVP_JUNE_9.md`: Актуальный план MVP.
Корневые файлы конфигурации Firebase:
  `.firebaserc`: Определяет алиасы проектов Firebase.
  `firebase.json`: Конфигурирует развертывание Firebase Hosting, Cloud Functions (включая указание исходной директории для функций, например, `backend`), Storage, Firestore (если используется) и настройки Firebase Local Emulator Suite.
Прочие файлы:
  `Dockerfile`: Может использоваться для вспомогательных задач или для развертывания специфических R&D сервисов вне Firebase, но не для основного бэкенда MVP.
  `[PROJECT_CONTEXT.md] (docs/00_OVERVIEW_AND_CONTEXT/PROJECT_CONTEXT.md)`: Актуальный срез состояния проекта.
  `[tria_memory_buffer.md] (docs/99_ARCHIVE/development_logs/tria_memory_buffer.md)`: Лог итераций разработки.

Сеть Ботов Триа (концептуально, реализуется в `backend/core/tria_bots/` и вызывается из Firebase Cloud Functions; в будущем оркестрируется Genkit):
AudioBot, GestureBot/VideoBot, MemoryBot, LearningBot, CoordinationService (Оркестратор – в будущем Genkit flow).

5. Блок-схема Верхнего Уровня (Обновлено для Firebase MVP)
*(Примечание: Mermaid-диаграмма ниже была обновлена для отражения архитектуры Firebase, но может требовать дальнейшей детализации для сложных взаимодействий.)*

**Пояснения к обновленной блок-схеме (Firebase MVP):**
1.  **Пользователь** взаимодействует с **Frontend (Firebase Hosting)**.
2.  Frontend использует **Firebase Authentication** для аутентификации пользователя (получение JWT токена).
3.  Для загрузки медиа-"чанков" (аудио, видео), Frontend напрямую обращается к **Firebase Storage**.
4.  Для выполнения бизнес-логики, отправки команд или текстовых данных, Frontend делает HTTPS-запросы к **Firebase Cloud Functions (Python)**, передавая JWT токен для авторизации.
5.  События в Firebase Storage (например, загрузка нового файла) также могут автоматически триггерить **Firebase Cloud Functions**.
6.  **Firebase Cloud Functions** являются ядром бэкенда:
    *   Проверяют JWT токен пользователя с помощью Firebase Admin SDK.
    *   Обрабатывают входящие HTTP-запросы и триггеры событий.
    *   Инкапсулируют или вызывают логику **Триа-Ботов** (модули в `backend/core/tria_bots/`).
    *   Взаимодействуют с **Neon.tech PostgreSQL + pgvector** (через `asyncpg` из `backend/core/db/`) для выполнения CRUD-операций, хранения метаданных, пользовательских данных и обеспечения RAG-функциональности.
    *   Обращаются к **Внешним LLM API** (например, Google Gemini через Firebase AI / Vertex AI, Mistral API) для генерации текста, анализа и других AI-задач.
    *   В будущем, эта логика будет постепенно мигрировать под управление **Genkit** flows для лучшей оркестрации.
7.  Cloud Functions возвращают HTTP-ответы (например, JSON) на Frontend.
8.  Frontend соответствующим образом обновляет UI, визуализацию голограммы, воспроизводит аудио и т.д.
9.  **HoloGraph (Блокчейн)** и связанные с ним P2P-механизмы остаются долгосрочным R&D направлением и не являются частью основного потока MVP.

graph LR
    A[Пользователь] -->|Жесты, Голос, Файлы, Команды| B(Frontend на Firebase Hosting)

    subgraph Firebase Ecosystem
        FB_AUTH[Firebase Authentication]
        FB_STORAGE[Firebase Storage]
        CF[Firebase Cloud Functions (Python)]
    end

    subgraph Backend Logic & Data
        TRIA_LOGIC{Логика Триа (Боты/Genkit в backend/core/)}
        DB[(Neon.tech PostgreSQL + pgvector)]
    end

    LLM_API[External LLM APIs (Gemini, Mistral)]
    HG[HoloGraph (Блокчейн) - R&D]

    B -- Аутентификация (JWT) --> FB_AUTH
    B -- Загрузка чанков (медиа) --> FB_STORAGE
    B -- Запросы API (HTTPS с JWT) --> CF

    FB_STORAGE -- Триггер (новый файл) --> CF
    CF -- Проверка токена --> FB_AUTH
    CF -- Данные/Команды --> TRIA_LOGIC
    TRIA_LOGIC -- CRUD, RAG --> DB
    TRIA_LOGIC -- Запросы --> LLM_API
    LLM_API -- Ответы --> TRIA_LOGIC
    DB -- Данные --> TRIA_LOGIC
    TRIA_LOGIC -- Результат --> CF
    CF -- HTTP Response --> B
    B -- Обновление UI/Голограммы --> A


(Цель этого глоссария – дать простое и понятное объяснение основных компонентов проекта, чтобы у всех участников, включая AI и НейроКодера, было единое понимание. Список будет пополняться по мере развития проекта.)
Основные Концепции:
Голограмма (Hologram): Динамическая трехмерная аудиовизуализация, являющаяся основным способом представления информации и взаимодействия в проекте. Генерируется и управляется с помощью WebGPU.
Триа (Tria): AI-ассистент и ядро проекта. Представляет собой сеть специализированных ботов, которые анализируют пользовательский ввод, генерируют реакции и обучаются на взаимодействиях. Цель Триа – "собрать себя сама" через эволюционные принципы.
Комбинированный Аудио(Видео)-Жестовый Чанк (Interaction Chunk): Основная единица данных, фиксирующая взаимодействие пользователя с системой. Включает синхронизированные аудиоданные, видеоданные (для анализа жестов и контекста), данные о распознанных жестах (координаты, параметры) и метаданные (время, ID пользователя, обратная связь). Используется для обучения Триа.
Симуляционно-Реальный Разрыв (Sim-to-Real Gap): Проблема переноса моделей AI, обученных в симуляции, в реальный мир. В нашем проекте – это разрыв между уникальными данными каждого пользователя и общей, но адаптивной моделью Триа. Преодолевается через обучение на разнообразных "чанках" от множества пользователей.
Новый Язык Коммуникации: Долгосрочная цель проекта – создание интуитивного языка, объединяющего звук, образ и жест, понятного как людям, так и AI.
HoloGraph (ранее "Инфокойн"): Рабочее название для децентрализованной экономической системы проекта. Предполагает использование токенов для вознаграждения пользователей за предоставление качественных "чанков" данных и вычислительных ресурсов, а также для управления развитием Триа и платформы (через DAO). Название "HoloGraph" подчеркивает связь с голограммами и графовой структурой знаний/взаимодействий.
Ключевые Директории и Файлы Проекта:
backend/: Содержит весь Python-код бэкенда.
backend/app.py: Основной файл FastAPI приложения, инициализирует приложение, подключает роутеры, управляет жизненным циклом.
backend/tria_bots/: Директория для модулей, реализующих отдельных ботов сети Триа (AudioBot, GestureBot, MemoryBot, LearningBot, CoordinationService).
backend/db/schema.sql: Определяет структуру базы данных PostgreSQL, включая таблицы `users`, `user_chat_sessions`, `chat_history`, `user_gestures`, `user_holograms`, `user_prompt_versions` и другие.
backend/db/crud_operations.py: Содержит функции для выполнения операций чтения, записи, обновления и удаления данных в PostgreSQL.
backend/auth/security.py: Функции для хэширования паролей, создания и проверки JWT токенов, зависимости для получения текущего пользователя.
backend/routers/auth.py: API эндпоинты для регистрации и аутентификации пользователей (`/auth/register`, `/auth/token`).
backend/routers/gestures.py: API эндпоинты для управления пользовательскими жестами (`/users/me/gestures`).
backend/routers/holograms.py: API эндпоинты для управления пользовательскими сохраненными состояниями голограмм (`/users/me/holograms`).
backend/routers/chat_sessions.py: API эндпоинты для управления сессиями чата и сообщениями (`/users/me/chat_sessions`).
backend/routers/prompts.py: API эндпоинты для управления версиями пользовательских промптов (`/users/me/prompts`).
backend/models/: Директория с Pydantic моделями, определяющими структуру данных для API запросов/ответов и для взаимодействия с базой данных.
    backend/models/user_models.py: Модели для пользователей (`UserCreate`, `UserPublic`, `UserInDB`).
    backend/models/auth_models.py: Модели для аутентификации (`Token`, `TokenData`).
    backend/models/gesture_models.py: Модели для жестов.
    backend/models/hologram_models.py: Модели для состояний голограмм.
    backend/models/chat_models.py: Модели для чат-сессий и сообщений.
    backend/models/prompt_models.py: Модели для версий промптов.
backend/requirements.txt: Список Python-зависимостей бэкенда.
backend/tests/: Юнит-тесты и интеграционные тесты для бэкенда.
backend/.venv/: (Рекомендуемое место) Виртуальное окружение Python для бэкенда.
frontend/: Содержит весь код фронтенда (HTML, CSS, JavaScript).
frontend/index.html: Единственная HTML-страница приложения (SPA).
frontend/style.css: Основные стили приложения.
frontend/js/: Корневая директория для всех JavaScript ES6 модулей.
frontend/js/main.js: Главная точка входа для фронтенда; импортирует и инициализирует все остальные JS модули.
frontend/js/core/: Базовые модули ядра фронтенда (init.js для state, events.js, resizeHandler.js, domEventHandlers.js, diagnostics.js).
frontend/js/3d/: Модули, связанные с 3D-графикой (sceneSetup.js для инициализации Three.js/WebGPU, handRenderer.js для отрисовки рук).
frontend/js/rendering.js: Общие функции для рендеринга аудиовизуализации, создания 3D-примитивов, основной цикл анимации animate().
frontend/js/ui/: Модули для управления различными частями пользовательского интерфейса (uiManager.js, panelManager.js, layoutManager.js, promptManager.js, versionManager.js, fileEditor.js, gestureAreaVisualization.js).
frontend/js/audio/: Модули для работы с аудио (microphoneManager.js, audioFilePlayer.js, speechInput.js).
frontend/js/multimodal/: Модули для обработки мультимодального ввода (например, handsTracking.js для MediaPipe Hands).
frontend/js/ai/: Модули для взаимодействия фронтенда с AI "Триа" (tria.js, chat.js).
frontend/js/panels/: Модули, специфичные для правой панели (chatMessages.js, rightPanelManager.js).
frontend/script.js: (УСТАРЕЛ, ПОДЛЕЖИТ УДАЛЕНИЮ) Монолитный JS файл, вся логика из которого переносится в модули в frontend/js/.
.github/workflows/: Файлы GitHub Actions для CI/CD (например, deploy-hf-space.yml).
Dockerfile: Инструкции для сборки Docker-образа приложения для развертывания.
[PROJECT_CONTEXT.md](../00_OVERVIEW_AND_CONTEXT/PROJECT_CONTEXT.md): Этот файл – актуальный срез состояния проекта, его целей, структуры. Основной источник контекста для AI.
[tria_memory_buffer.md](../99_ARCHIVE/development_logs/tria_memory_buffer.md): Детальный лог итераций разработки, решений и изменений. Обновляется после каждого значимого шага.
Ключевые Файлы Конфигурации (в корне):
.env: Локальные переменные окружения (ключи API, строки подключения к БД). Не коммитится в Git.
.gitignore: Определяет файлы и папки, которые Git должен игнорировать.
package.json: Определяет JS-зависимости (если используются npm-пакеты) и скрипты для сборки/линтеров.
eslint.config.mjs (или .eslintrc.js): Конфигурация ESLint для статического анализа JavaScript кода.
Сеть Ботов Триа (концептуально, реализуется в backend/tria_bots/):
AudioBot: Отвечает за анализ входящего аудио (из "чанков", с микрофона) и синтез звуковых реакций. Использует вейвлет-преобразования.
GestureBot / VideoBot: Анализирует данные жестов (MediaPipe) и видео-контекст из "чанков". Классифицирует жесты, извлекает их параметры, генерирует векторные представления.
MemoryBot: "Долговременная память" Триа. Взаимодействует с PostgreSQL (pgvector) для хранения и извлечения "чанков", выученных паттернов "жест-смысл-реакция", пользовательских предпочтений. Реализует RAG.
LearningBot: "Мозг" обучения Триа. Анализирует эффективность других ботов на основе "чанков" и обратной связи. Реализует эволюционные алгоритмы (генерация, мутация, отбор) для улучшения моделей и конфигураций других ботов.
CoordinationService (Оркестратор): Получает входящие данные/запросы, распределяет задачи между ботами, агрегирует их ответы и формирует финальную реакцию Триа.
Блок-схема Верхнего Уровня (Концептуальная)
graph LR
    A[Пользователь] -->|Жест, Голос, Контекст| B(Frontend)
    B -->|Interaction Chunk (HTTP/WebSocket)| C{Backend (FastAPI)}
    C -->|Данные чанка| D[Coordination Service / Tria Orchestrator]
    D --> E[GestureBot / VideoBot]
    D --> F[AudioBot]
    E --> G[MemoryBot (PostgreSQL + pgvector)]
    F --> G
    G --> E
    G --> F
    D --> H[LearningBot (Эволюция, Анализ)]
    H --> E
    H --> F
    H --> G
    D --> I[Ответ Триа (Команды визуализации, Аудио, Текст)]
    I --> C
    C -->|Обновление UI, Голограммы, Звук| B
    B --> A

    J[База Данных PostgreSQL + pgvector]
    G <--> J
    H <--> J

    K[HoloGraph (Блокчейн)]
    L[Данные о вкладе пользователя] --> K
    M[Вычислительные ресурсы] --> K
    K -->|Вознаграждение| A
    K -->|Управление| H
Use code with caution.
Mermaid
Пояснения к блок-схеме:
Пользователь взаимодействует с Frontend.
Frontend формирует Interaction Chunk и отправляет на Backend.
Backend (FastAPI) передает чанк Координатору Триа.
Координатор распределяет задачи между GestureBot, AudioBot.
Эти боты могут обращаться к MemoryBot для получения контекста из Базы Данных PostgreSQL (pgvector).
LearningBot асинхронно анализирует данные из БД и обратную связь, обновляя другие боты (эволюция).
Координатор формирует Ответ Триа и отправляет его на Frontend.
Frontend обновляет UI, Голограмму, воспроизводит звук.
Система HoloGraph (Блокчейн) учитывает вклад пользователя (данные, ресурсы) и может управлять развитием Триа.
Этот расширенный раздел должен дать гораздо лучшее понимание как статической структуры, так и динамики работы проекта. Его нужно будет поддерживать в актуальном состоянии.

Пояснения к блок-схеме:
Пользователь взаимодействует с Frontend.
Frontend формирует Interaction Chunk и отправляет на Backend.
Backend (FastAPI) передает чанк Координатору Триа.
Координатор распределяет задачи между GestureBot, AudioBot.
Эти боты могут обращаться к MemoryBot для получения контекста из Базы Данных PostgreSQL (pgvector).
LearningBot асинхронно анализирует данные из БД и обратную связь, обновляя другие боты (эволюция).
Координатор формирует Ответ Триа и отправляет его на Frontend.
Frontend обновляет UI, Голограмму, воспроизводит звук.
Система HoloGraph (Блокчейн) учитывает вклад пользователя (данные, ресурсы) и может управлять развитием Триа.

## 6. Future Directions and Long-Term Vision Integration (Placeholder)

This section is intended to outline near-to-mid-term architectural evolution and how foundational principles for longer-term goals (such as those discussed in the "Visionary Architecture & Foundational Scaffolding" research) will be integrated.

*(Detailed content for this section will be developed based on ongoing research, strategic decisions, and concepts previously outlined in `FUTUREARCHITECTURE.MD`. Note: `FUTUREARCHITECTURE.MD` was not found during the latest consolidation effort, so its specific inputs could not be directly merged at this time. This section will be updated as these concepts are further refined and prioritized.)*

Key areas for future consideration include:
-   **NetHoloGlyph Protocol:** Maturing the protocol for rich, real-time holographic communication.
-   **Advanced Gestural Programming:** Evolving `GestureBot` and interaction models for more complex "sculpted" logic.
-   **"Liquid Code" Concepts:** Exploring how code embeddings could allow Tria to understand and evolve its own logic.
-   **Tria's Self-Evolution (AZR):** Implementing robust Absolute Zero Reasoning cycles for autonomous capability growth.
-   **HoloGraph Tokenomics:** Detailing data structures and system interactions for the token-based ecosystem.

---
# FUTUREARCHITECTURE.md: Будущая архитектура проекта "Голографические Медиа"

**Версия**: 1.0  
**Дата создания**: 20 мая 2025  
**Репозиторий**: [https://github.com/NeuroCoderZ/holograms.media](https://github.com/NeuroCoderZ/holograms.media)  
**Лицензия**: MIT  

---

## 1. Введение

На 20 мая 2025 года проект "Голографические Медиа" — это амбициозная платформа с открытым исходным кодом (MIT), создающая интерактивные 3D-аудиовизуализации ("голограммы") через мультимодальные интерфейсы (жесты, голос, биометрия) и сеть ИИ-ботов "Триа". Основываясь на текущем состоянии (версия 2.1 `ARCHITECTURE.md`), мы проектируем будущее архитектуры на 2035-2040 годы, интегрируя квантовые вычисления, нейроморфные системы, голографические дисплеи и глобальные нейронные сети. Цель — переосмыслить коммуникацию, создав универсальный язык для людей и ИИ, интегрированный в метавселенные.

---

## 2. Технологические инновации

### 2.1. Квантовые вычисления
- **Семантический поиск**: Квантовый алгоритм Гровера для поиска по миллиардам векторных эмбеддингов с ускорением в 100 раз (доступно к 2035 году).
- **Оптимизация ИИ**: Квантовые нейронные сети (QNN) для обучения моделей Триа, снижая энергопотребление на 70% (прототипы к 2030, массовое применение к 2040).
- **Реалистичность**: К 2025 году доступны процессоры с 100 кубитами (IBM Quantum), к 2035 ожидается 10 000 кубитов.

### 2.2. Нейроморфные системы
- **Обработка данных**: Чипы Intel Loihi 3 для спайковых нейронных сетей, обеспечивающие реальное время обработки жестов и звука с энергопотреблением <1 Вт (к 2030).
- **Самообучение**: Адаптивные нейрочипы, обновляющие модели Триа на лету без серверов (к 2035).
- **Реалистичность**: Текущие тесты (2025) показывают эффективность на 50% выше GPU, массовое производство к 2032.

### 2.3. Голографические дисплеи и интерфейсы
- **Light Field Displays**: Полное 3D-изображение без гарнитур, использующее голографические проекторы (например, от Holoxica, к 2035).
- **Нейронные интерфейсы**: Прямое управление голограммами через мозговые сигналы с устройствами уровня Neuralink 3.0 (к 2040).
- **Пример**: Пользователь мысленно "рисует" голограмму, а система интерпретирует сигналы через EEG и синтезирует 3D-объект.

### 2.4. Глобальные нейронные сети
- **Децентрализация**: Распределённая сеть ИИ-нод по всему миру, работающая на принципах P2P (к 2038).
- **Обучение**: Общая память системы через квантовые ассоциативные массивы (к 2040).
- **Пример**: Глобальная база жестов, доступная в реальном времени для всех пользователей.

---

## 3. Архитектурные улучшения

### 3.1. Оптимизация производительности
- **Векторизация**: Использование квантовых Sparse Autoencoders для обработки жестов с компрессией 95% (2035).
- **Кэширование**: Глобальная квантово-оптическая память для хранения эмбеддингов (2040).
- **Обработка**: Нейроморфные кластеры для параллельного рендеринга голограмм (2035).

### 3.2. Надежность
- **Circuit Breaker**: Распределённая защита через нейроморфные контроллеры (2030).
- **Криптография**: Постквантовая защита с CRYSTALS-Kyber и квантовым ключевым обменом (2035).
- **Мониторинг**: ИИ-система предсказания сбоев на основе нейронных сетей (2032).

### 3.3. Расширение функциональности
- **Нейроинтерфейсы**: Поддержка Emotiv Insight для управления голограммами через мысли (2030).
- **Голографический DAO**: Управление через смарт-контракты с голосованием HoloCoins (2035).
- **Метавселенные**: Интеграция с глобальными платформами через открытый протокол HoloComm (2040).

---

## 4. Экосистема и экономическая модель

### 4.1. Эволюция HoloGraph
- **Токенизация**: HoloCoins как универсальная валюта для ресурсов и управления (2030).
- **DAO 2.0**: Автономное управление через квантово-устойчивые контракты (2035).
- **Сравнение**: По сравнению с Ethereum 2.0, HoloGraph использует квантовые орáculos для прозрачности (2040).
- **Риски**: Зависимость от квантовых технологий и волатильность токенов.

### 4.2. Экономическая устойчивость
- **Модель**: Подписка ($50/месяц) и лицензирование технологий (2035).
- **Партнёрства**: Сотрудничество с Google (квантовые вычисления) и Microsoft (нейроморфные чипы).
- **Финансирование**: $10 млн через Horizon Europe и частные инвесторы (2025-2030).

---

## 5. Перспективы развития

### 5.1. Интеграция с метавселенными
- **Стандарты**: HoloComm как глобальный протокол для обмена голограммами (2038).
- **Платформы**: Интеграция с Meta Horizon и Decentraland (2040).

### 5.2. Универсальный язык
- **Разработка**: ИИ-генерация языка на основе культурных данных (2035).
- **Применение**: Перевод жестов и звуков в реальном времени (2040).

### 5.3. Экосистема
- **SDK**: Плагин для создания голограмм через голосовые команды (2030).
- **Сообщество**: Открытый доступ для разработчиков (2035).

---

## Заключение

К 2040 году "Голографические Медиа" станут пионером в иммерсивной коммуникации, интегрируя квантовые вычисления, нейроморфные системы и голографические интерфейсы. Эволюция от текущего состояния (версия 2.1, 2025) к этой архитектуре создаст платформу, переопределяющую взаимодействие человека с ИИ, с глобальным охватом и устойчивой экономикой.
