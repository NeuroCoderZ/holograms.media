# CRUD operations for database interaction
import asyncpg
from typing import Optional, Any, Dict # Added Dict for JSON types
from uuid import uuid4, UUID # Added UUID
from datetime import datetime

# Assuming UserModel is in a sibling directory 'models'
# Adjust the import path if your project structure is different.
# from backend.core.models.user_models import UserModel
# Correcting relative import based on file location:
from ..models.user_models import UserModel
from ..models.multimodal_models import AudiovisualGesturalChunkModel
from ..models.learning_log_models import TriaLearningLogModel


async def create_user(db: asyncpg.Connection, *, user_create: UserModel) -> UserModel:
    """
    Creates a new user record in the database.

    Args:
        db: An active asyncpg database connection.
        user_create: A Pydantic UserModel containing the user data to create.
                     The `user_id_firebase` field will be used as the `user_id` primary key
                     in the 'users' table. The `id` (UUID) field of UserModel is not
                     stored in the 'users' table and will be generated locally.

    Returns:
        A UserModel instance representing the created user, including data
        fetched from the database (like created_at, updated_at) and a locally
        generated UUID for the 'id' field.

    Raises:
        asyncpg.PostgresError: If a database error occurs (e.g., unique constraint violation).
    """
    sql = """
        INSERT INTO users (user_id, email)
        VALUES ($1, $2)
        RETURNING user_id, email, created_at, updated_at;
    """
    try:
        row = await db.fetchrow(sql, user_create.user_id_firebase, user_create.email)
        if row:
            # The 'id' field (UUID) from BaseUUIDModel is not in the 'users' table.
            # We generate a new UUID for it here as the Pydantic model expects it.
            # created_at and updated_at from the DB are timezone-aware (TIMESTAMPTZ)
            # asyncpg returns them as Python datetime objects.
            return UserModel(
                id=uuid4(), # Not from DB, generated locally
                user_id_firebase=row['user_id'],
                email=row['email'],
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )
        else:
            # This case should ideally not be reached if RETURNING is used and insert is successful.
            # Consider raising an error or handling more robustly.
            raise Exception("User creation failed, no data returned.")

    except asyncpg.UniqueViolationError as e:
        # Specific handling for unique constraint violations (e.g., email or user_id already exists)
        # You might want to log this or raise a custom application-level exception
        print(f"Error creating user: {e}") # Replace with proper logging
        raise # Re-raise the exception


async def get_user_by_firebase_uid(db: asyncpg.Connection, firebase_uid: str) -> Optional[UserModel]:
    """
    Retrieves a user from the database by their Firebase UID.

    Args:
        db: An active asyncpg database connection.
        firebase_uid: The Firebase UID (maps to 'user_id' column) of the user to retrieve.

    Returns:
        A UserModel instance if the user is found, otherwise None.
        The 'id' (UUID) field of the returned UserModel is generated locally
        as it's not stored in the 'users' table.
    """
    sql = """
        SELECT user_id, email, created_at, updated_at
        FROM users
        WHERE user_id = $1;
    """
    row = await db.fetchrow(sql, firebase_uid)
    if row:
        # The 'id' field (UUID) from BaseUUIDModel is not in the 'users' table.
        # We generate a new UUID for it here.
        return UserModel(
            id=uuid4(), # Not from DB, generated locally
            user_id_firebase=row['user_id'],
            email=row['email'],
            created_at=row['created_at'],
            updated_at=row['updated_at']
        )
    return None


async def create_tria_learning_log_entry(
    db: asyncpg.Connection, *, log_entry_create: TriaLearningLogModel
) -> TriaLearningLogModel:
    """
    Creates a new Tria learning log entry in the database.
    The `log_id` is auto-generated by the database.
    The `timestamp` from the input model is used.
    """
    sql = """
        INSERT INTO tria_learning_log (
            event_type, bot_affected_id, summary_text, details_json, timestamp
        ) VALUES (
            $1, $2, $3, $4, $5
        )
        RETURNING
            log_id, timestamp, event_type, bot_affected_id, summary_text, details_json;
    """
    try:
        row = await db.fetchrow(
            sql,
            log_entry_create.event_type,
            log_entry_create.bot_affected_id,
            log_entry_create.summary_text,
            log_entry_create.details_json,
            log_entry_create.timestamp, # Explicitly passing the timestamp from the model
        )
        if row:
            # Map the database row back to the Pydantic model
            return TriaLearningLogModel(
                log_id=row['log_id'],
                timestamp=row['timestamp'],
                event_type=row['event_type'],
                bot_affected_id=row['bot_affected_id'],
                summary_text=row['summary_text'],
                details_json=row['details_json']
            )
        else:
            # This case should ideally not be reached if RETURNING is used and insert is successful.
            raise Exception("TriaLearningLog entry creation failed, no data returned.")
    except asyncpg.PostgresError as e:
        # Log the error or raise a custom application-level exception
        print(f"Error creating Tria learning log entry: {e}") # Replace with proper logging
        raise

# Example of how these functions might be called (for illustration, not part of the script):
# async def main():
#     # Assume NEON_DATABASE_URL is set in the environment
#     # from backend.core.db.pg_connector import get_db_connection
#
#     conn = None
#     try:
#         # conn = await get_db_connection() # This would come from pg_connector.py
#
#         # Dummy connection for testing without actual DB
#         class DummyConnection:
#             async def fetchrow(self, query, *args):
#                 print(f"Executing query: {query} with args: {args}")
#                 if "INSERT" in query and args[0] == "test_firebase_uid_123":
#                     return {
#                         "user_id": args[0], "email": args[1],
#                         "created_at": datetime.utcnow(), "updated_at": datetime.utcnow()
#                     }
#                 if "SELECT" in query and args[0] == "test_firebase_uid_123":
#                     return {
#                         "user_id": args[0], "email": "test@example.com",
#                         "created_at": datetime.utcnow(), "updated_at": datetime.utcnow()
#                     }
#                 return None
#
#         conn = DummyConnection()
#
#         # Create a user
#         user_to_create = UserModel(
#             user_id_firebase="test_firebase_uid_123",
#             email="test@example.com",
#             # id, created_at, updated_at will be set by default_factory or in create_user
#         )
#         created_user = await create_user(db=conn, user_create=user_to_create)
#         if created_user:
#             print(f"Created user: {created_user.model_dump_json(indent=2)}")
#
#         # Get a user
#         retrieved_user = await get_user_by_firebase_uid(db=conn, firebase_uid="test_firebase_uid_123")
#         if retrieved_user:
#             print(f"Retrieved user: {retrieved_user.model_dump_json(indent=2)}")
#
#         non_existent_user = await get_user_by_firebase_uid(db=conn, firebase_uid="non_existent_uid")
#         if not non_existent_user:
#             print("Correctly did not find non_existent_user.")
#
#     except Exception as e:
#         print(f"An error occurred: {e}")
#     # finally:
#     #     if conn and hasattr(conn, 'close'): # Real connection would have close
#     #         await conn.close()

# if __name__ == "__main__":
#     import asyncio
#     asyncio.run(main())


async def create_audiovisual_gestural_chunk(
    db: asyncpg.Connection, *, chunk_create: AudiovisualGesturalChunkModel
) -> AudiovisualGesturalChunkModel:
    """
    Creates a new audiovisual/gestural chunk record in the database.
    The `id` field of the input `chunk_create` model (which is a UUID) is used as `chunk_id` PK.
    `created_at` and `updated_at` are set by the database.
    """
    sql = """
        INSERT INTO audiovisual_gestural_chunks (
            chunk_id, user_id, chunk_type, storage_ref,
            original_filename, mime_type, duration_seconds,
            resolution_width, resolution_height,
            tria_processing_status, tria_extracted_features_json,
            related_gesture_id, related_hologram_id, custom_metadata_json
            -- created_at and updated_at are handled by DB defaults
        ) VALUES (
            $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14
        )
        RETURNING
            chunk_id, user_id, chunk_type, storage_ref,
            original_filename, mime_type, duration_seconds,
            resolution_width, resolution_height,
            tria_processing_status, tria_extracted_features_json,
            related_gesture_id, related_hologram_id, custom_metadata_json,
            created_at, updated_at;
    """
    try:
        row = await db.fetchrow(
            sql,
            chunk_create.id,  # Maps to chunk_id
            chunk_create.user_id,
            chunk_create.chunk_type,
            chunk_create.storage_ref,
            chunk_create.original_filename,
            chunk_create.mime_type,
            chunk_create.duration_seconds,
            chunk_create.resolution_width,
            chunk_create.resolution_height,
            chunk_create.tria_processing_status,
            chunk_create.tria_extracted_features_json,
            chunk_create.related_gesture_id,
            chunk_create.related_hologram_id,
            chunk_create.custom_metadata_json,
        )
        if row:
            # Map the database row back to the Pydantic model
            # The 'id' field in Pydantic model corresponds to 'chunk_id' in the DB table.
            return AudiovisualGesturalChunkModel(
                id=row['chunk_id'],
                user_id=row['user_id'],
                chunk_type=row['chunk_type'],
                storage_ref=row['storage_ref'],
                original_filename=row['original_filename'],
                mime_type=row['mime_type'],
                duration_seconds=row['duration_seconds'],
                resolution_width=row['resolution_width'],
                resolution_height=row['resolution_height'],
                tria_processing_status=row['tria_processing_status'],
                tria_extracted_features_json=row['tria_extracted_features_json'],
                related_gesture_id=row['related_gesture_id'],
                related_hologram_id=row['related_hologram_id'],
                custom_metadata_json=row['custom_metadata_json'],
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )
        else:
            # This case should ideally not be reached if RETURNING is used and insert is successful.
            raise Exception("AudiovisualGesturalChunk creation failed, no data returned.")
    except asyncpg.PostgresError as e:
        # Log the error or raise a custom application-level exception
        print(f"Error creating audiovisual/gestural chunk: {e}") # Replace with proper logging
        raise


async def get_chunk_by_id(db: asyncpg.Connection, chunk_id: UUID) -> Optional[AudiovisualGesturalChunkModel]:
    """
    Retrieves an audiovisual/gestural chunk from the database by its ID.
    """
    sql = """
        SELECT
            chunk_id, user_id, chunk_type, storage_ref,
            original_filename, mime_type, duration_seconds,
            resolution_width, resolution_height,
            tria_processing_status, tria_extracted_features_json,
            related_gesture_id, related_hologram_id, custom_metadata_json,
            created_at, updated_at
        FROM audiovisual_gestural_chunks
        WHERE chunk_id = $1;
    """
    row = await db.fetchrow(sql, chunk_id)
    if row:
        return AudiovisualGesturalChunkModel(
            id=row['chunk_id'],
            user_id=row['user_id'],
            chunk_type=row['chunk_type'],
            storage_ref=row['storage_ref'],
            original_filename=row['original_filename'],
            mime_type=row['mime_type'],
            duration_seconds=row['duration_seconds'],
            resolution_width=row['resolution_width'],
            resolution_height=row['resolution_height'],
            tria_processing_status=row['tria_processing_status'],
            tria_extracted_features_json=row['tria_extracted_features_json'],
            related_gesture_id=row['related_gesture_id'],
            related_hologram_id=row['related_hologram_id'],
            custom_metadata_json=row['custom_metadata_json'],
            created_at=row['created_at'],
            updated_at=row['updated_at']
        )
    return None
